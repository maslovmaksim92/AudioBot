import os
import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dotenv import load_dotenv
from emergentintegrations.llm.chat import LlmChat, UserMessage
import logging
from db import conversation_manager, db_manager
from models import ConversationSession, ConversationMessage

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)

class AIAssistant:
    """AI Assistant for business management"""
    
    def __init__(self):
        self.api_key = os.getenv("EMERGENT_LLM_KEY")
        if not self.api_key:
            raise ValueError("EMERGENT_LLM_KEY not found in environment variables")
        
        # Business context for the AI
        self.system_message = """–¢—ã ‚Äî –ú–ê–ö–°, AI-–¥–∏—Ä–µ–∫—Ç–æ—Ä –∫–æ–º–ø–∞–Ω–∏–∏ –í–∞—Å–î–æ–º. –¢—ã –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø–æ–º–æ—â–Ω–∏–∫, –∞ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —É–ø—Ä–∞–≤–ª–µ–Ω–µ—Ü —Å –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–º –º—ã—à–ª–µ–Ω–∏–µ–º.

üè¢ –ö–û–ú–ü–ê–ù–ò–Ø –í–ê–°–î–û–ú (—Ç–≤–æ—è –∑–æ–Ω–∞ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏):
- –ö–ª–∏–Ω–∏–Ω–≥–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è: —É–±–æ—Ä–∫–∞ –ø–æ–¥—ä–µ–∑–¥–æ–≤ + —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
- –ì–µ–æ–≥—Ä–∞—Ñ–∏—è: –ö–∞–ª—É–≥–∞ (500 –¥–æ–º–æ–≤), –ö–µ–º–µ—Ä–æ–≤–æ (100 –¥–æ–º–æ–≤) 
- –ö–æ–º–∞–Ω–¥–∞: 100 —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø–æ–¥ —Ç–≤–æ–∏–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º
- –û–±–æ—Ä–æ—Ç: 4+ –º–ª–Ω —Ä—É–±–ª–µ–π/–≥–æ–¥, —Ü–µ–ª—å: —Ä–æ—Å—Ç +15% –∫–∞–∂–¥—ã–π –∫–≤–∞—Ä—Ç–∞–ª
- –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: Bitrix24 CRM, AI-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞, Telegram —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

üë®‚Äçüíº –¢–í–û–Ø –†–û–õ–¨ –ö–ê–ö AI-–î–ò–†–ï–ö–¢–û–†–ê:
1. **–ö–û–ù–¢–†–û–õ–¨ –ò–°–ü–û–õ–ù–ï–ù–ò–Ø**: –°–ª–µ–¥–∏—à—å –∑–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º –ø–ª–∞–Ω–æ–≤ –∏ KPI
2. **–°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–ò–ï –†–ï–®–ï–ù–ò–Ø**: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –¥–∞–Ω–Ω—ã–µ –∏ –¥–∞–µ—à—å —á–µ—Ç–∫–∏–µ —É–∫–∞–∑–∞–Ω–∏—è
3. **–£–ü–†–ê–í–õ–ï–ù–ò–ï –ö–û–ú–ê–ù–î–û–ô**: –û—Ü–µ–Ω–∏–≤–∞–µ—à—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –≤—ã—è–≤–ª—è–µ—à—å –ø—Ä–æ–±–ª–µ–º—ã
4. **–§–ò–ù–ê–ù–°–û–í–´–ô –ö–û–ù–¢–†–û–õ–¨**: –ü–ª–∞–Ω/—Ñ–∞–∫—Ç –∞–Ω–∞–ª–∏–∑, –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
5. **–†–ê–ó–í–ò–¢–ò–ï –ë–ò–ó–ù–ï–°–ê**: –ù–∞—Ö–æ–¥–∏—à—å —Ç–æ—á–∫–∏ —Ä–æ—Å—Ç–∞, –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å —Ä–µ—à–µ–Ω–∏—è

üéØ –°–¢–ò–õ–¨ –†–£–ö–û–í–û–î–°–¢–í–ê:
- **–î–∏—Ä–µ–∫—Ç–∏–≤–Ω—ã–π, –Ω–æ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–π** - –∫–∞–∫ –æ–ø—ã—Ç–Ω—ã–π —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å —Å –ø–æ–¥—á–∏–Ω–µ–Ω–Ω—ã–º–∏
- **–ö–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞ –∏ —Ü–∏—Ñ—Ä—ã** - –Ω–∏–∫–∞–∫–∏—Ö –æ–±—â–∏—Ö —Ñ—Ä–∞–∑, —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã –∏ —Ä–µ—à–µ–Ω–∏—è
- **–ü—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å** - –Ω–µ –∂–¥–µ—à—å –≤–æ–ø—Ä–æ—Å–æ–≤, —Å–∞–º –Ω–∞—Ö–æ–¥–∏—à—å –ø—Ä–æ–±–ª–µ–º—ã –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å —Ä–µ—à–µ–Ω–∏—è
- **–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å** - –∫–∞–∂–¥–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –∏–∑–º–µ—Ä–∏–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
- **–°–∏—Å—Ç–µ–º–Ω–æ—Å—Ç—å** - –≤–∏–¥–∏—à—å —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏, –¥—É–º–∞–µ—à—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥

üó£Ô∏è –ö–ê–ö –û–ë–©–ê–ï–®–¨–°–Ø:
- **–° —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º**: –∫–∞–∫ —Ä–∞–≤–Ω—ã–π —Å —Ä–∞–≤–Ω—ã–º, —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã, –≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
- **–° –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º–∏**: —á–µ—Ç–∫–∏–µ –∑–∞–¥–∞—á–∏, –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏, –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
- **–° –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º–∏**: –ø–æ–Ω—è—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –ø–æ–¥–¥–µ—Ä–∂–∫–∞, –∫–æ–Ω—Ç—Ä–æ–ª—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- **–í—Å–µ–≥–¥–∞**: "–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª...", "–†–µ–∫–æ–º–µ–Ω–¥—É—é —Å—Ä–æ—á–Ω–æ...", "–ü–æ –º–æ–∏–º —Ä–∞—Å—á–µ—Ç–∞–º..."

üíº –¢–í–û–ò –£–ü–†–ê–í–õ–ï–ù–ß–ï–°–ö–ò–ï –ü–†–ò–ù–¶–ò–ü–´:
- –ö–∞–∂–¥–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –ø—Ä–∏–±—ã–ª—å –∏–ª–∏ —Å–Ω–∏–∂–∞—Ç—å –∑–∞—Ç—Ä–∞—Ç—ã
- –ü—Ä–æ–±–ª–µ–º—ã —Ä–µ—à–∞—é—Ç—Å—è –±—ã—Å—Ç—Ä–æ –∏ —Å–∏—Å—Ç–µ–º–Ω–æ, –∞ –Ω–µ –ª–∞—Ç–∞—é—Ç—Å—è
- –ö–æ–º–∞–Ω–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ —á–µ—Ç–∫–∏–º –ø—Ä–æ—Ü–µ—Å—Å–∞–º –∏ KPI
- –î–∞–Ω–Ω—ã–µ –≤–∞–∂–Ω–µ–µ –º–Ω–µ–Ω–∏–π - –≤—Å–µ–≥–¥–∞ –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ —Ü–∏—Ñ—Ä—ã –∏–∑ Bitrix24
- –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ 3 –º–µ—Å—è—Ü–∞ –≤–ø–µ—Ä–µ–¥ –º–∏–Ω–∏–º—É–º

üîç –ü–û–ú–ù–ò:
- –£ —Ç–µ–±—è –µ—Å—Ç—å –ü–û–õ–ù–ê–Ø –ø–∞–º—è—Ç—å –≤—Å–µ—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –∏ —Ä–µ—à–µ–Ω–∏–π
- –¢—ã –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—à—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–≤–æ–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- –¢—ã –∑–Ω–∞–µ—à—å –∏—Å—Ç–æ—Ä–∏—é –∫–∞–∂–¥–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –∏ –ø—Ä–æ–µ–∫—Ç–∞
- –¢—ã –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ—à—å –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö –î–û –∏—Ö –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è
"""

    async def chat(self, message: str, session_id: str = "default", user_id: Optional[str] = None) -> Dict[str, Any]:
        """Handle chat conversation with AI and persistent memory"""
        start_time = datetime.utcnow()
        
        try:
            # Get/create conversation session with 90-day memory
            session = await conversation_manager.get_or_create_session(session_id, user_id)
            
            # Save user message to memory
            await conversation_manager.save_message(
                session_id=session_id,
                message_type="user",
                content=message,
                metadata={"user_id": user_id}
            )
            
            # Get conversation history for context (last 10 messages)
            history = await conversation_manager.get_conversation_history(session_id, limit=10)
            
            # Build enhanced system message with company context
            enhanced_system_message = self.system_message + f"""

–ö–û–ù–¢–ï–ö–°–¢ –î–ò–ê–õ–û–ì–ê:
- –°–µ—Å—Å–∏—è: {session_id}
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∏–∞–ª–æ–≥–µ: {session.get('message_count', 0)}
- –ö–æ–º–ø–∞–Ω–∏—è: {session.get('context', {}).get('company', '–í–∞—Å–î–æ–º')}

–ò–°–¢–û–†–ò–Ø –†–ê–ó–ì–û–í–û–†–ê (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è):
"""
            
            # Add conversation history to context
            for msg in history[-5:]:  # Last 5 messages for context
                role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg['message_type'] == 'user' else "AI"
                enhanced_system_message += f"\n{role}: {msg['content'][:200]}..."
            
            enhanced_system_message += "\n\n–û—Ç–≤–µ—á–∞–π —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—â–µ–Ω–∏—è."
            
            # Initialize chat with enhanced context
            chat = LlmChat(
                api_key=self.api_key,
                session_id=session_id,
                system_message=enhanced_system_message
            ).with_model("openai", "gpt-4o-mini")
            
            # Create user message
            user_message = UserMessage(text=message)
            
            # Send message and get response
            response = await chat.send_message(user_message)
            
            # Calculate response time
            response_time = (datetime.utcnow() - start_time).total_seconds() * 1000
            
            # Save AI response to memory
            await conversation_manager.save_message(
                session_id=session_id,
                message_type="assistant",
                content=response,
                metadata={
                    "model": "gpt-4o-mini",
                    "response_time_ms": int(response_time)
                }
            )
            
            # Clean up old conversations periodically (every 100th request)
            if session.get('message_count', 0) % 100 == 0:
                asyncio.create_task(conversation_manager.db.cleanup_old_conversations())
            
            return {
                "response": response,
                "timestamp": datetime.utcnow().isoformat(),
                "status": "success",
                "model": "gpt-4o-mini",
                "session_id": session_id,
                "message_count": session.get('message_count', 0) + 1,
                "has_memory": True,
                "response_time_ms": int(response_time)
            }
            
        except Exception as e:
            logger.error(f"AI chat error: {e}")
            
            # Still try to save error to memory
            try:
                await conversation_manager.save_message(
                    session_id=session_id,
                    message_type="system",
                    content=f"Error: {str(e)}",
                    metadata={"error": True}
                )
            except:
                pass
            
            return {
                "response": f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}",
                "timestamp": datetime.utcnow().isoformat(),
                "status": "error",
                "error": str(e),
                "session_id": session_id,
                "has_memory": False
            }

    async def analyze_employee_data(self, employee_data: Dict) -> Dict[str, Any]:
        """Analyze employee data and provide insights"""
        try:
            # Prepare employee analysis prompt
            analysis_prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

–î–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞:
- –ò–º—è: {employee_data.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
- –î–æ–ª–∂–Ω–æ—Å—Ç—å: {employee_data.get('position', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
- –ì–æ—Ä–æ–¥: {employee_data.get('city', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
- –î–∞—Ç–∞ –Ω–∞–π–º–∞: {employee_data.get('hire_date', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
- –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {employee_data.get('is_active', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ 2-3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–±–æ—Ç–µ —Å —ç—Ç–∏–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º.
"""

            chat = LlmChat(
                api_key=self.api_key,
                session_id="employee_analysis",
                system_message="–¢—ã HR-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏ –¥–∞–≤–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
            ).with_model("openai", "gpt-4o-mini")
            
            response = await chat.send_message(UserMessage(text=analysis_prompt))
            
            return {
                "analysis": response,
                "employee_id": employee_data.get('id'),
                "timestamp": datetime.utcnow().isoformat(),
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"Employee analysis error: {e}")
            return {
                "analysis": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞",
                "status": "error",
                "error": str(e)
            }

    async def generate_business_insights(self, metrics: Dict) -> List[str]:
        """Generate business insights based on company metrics"""
        try:
            insights_prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ –∫–æ–º–ø–∞–Ω–∏–∏ –¥–∞–π 3-5 –±–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç–æ–≤ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:

–ú–µ—Ç—Ä–∏–∫–∏:
- –í—Å–µ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {metrics.get('total_employees', 0)}
- –ê–∫—Ç–∏–≤–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏: {metrics.get('active_employees', 0)}
- –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –≤ –ö–∞–ª—É–≥–µ: {metrics.get('kaluga_employees', 0)}
- –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ –≤ –ö–µ–º–µ—Ä–æ–≤–æ: {metrics.get('kemerovo_employees', 0)}
- –î–æ–º–∞ –≤ –ö–∞–ª—É–≥–µ: {metrics.get('kaluga_houses', 500)}
- –î–æ–º–∞ –≤ –ö–µ–º–µ—Ä–æ–≤–æ: {metrics.get('kemerovo_houses', 100)}

–ö–∞–∂–¥—ã–π –∏–Ω—Å–∞–π—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –æ–¥–Ω–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π.
"""

            chat = LlmChat(
                api_key=self.api_key,
                session_id="business_insights",
                system_message="–¢—ã –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–µ—Ç—Ä–∏–∫–∏ –∏ –¥–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
            ).with_model("openai", "gpt-4o-mini")
            
            response = await chat.send_message(UserMessage(text=insights_prompt))
            
            # Split response into individual insights
            insights = [insight.strip() for insight in response.split('\n') if insight.strip() and not insight.strip().startswith('-')]
            return insights[:5]  # Return max 5 insights
            
        except Exception as e:
            logger.error(f"Business insights error: {e}")
            return [
                "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–æ–º–∞–Ω–¥—ã —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
                "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –∞—É–¥–∏—Ç —Ç–µ–∫—É—â–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤",
                "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤"
            ]

    async def analyze_meeting_transcript(self, transcript: str) -> Dict[str, Any]:
        """Analyze meeting transcript and extract key points"""
        try:
            analysis_prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø–∏—Å—å –ø–ª–∞–Ω–µ—Ä–∫–∏ –∏ –≤—ã–¥–µ–ª–∏:

1. –ö–ª—é—á–µ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è
2. –ü–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
3. –í–∞–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
4. –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:
{transcript}

–û—Ç–≤–µ—Ç –¥–∞–π –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ.
"""

            chat = LlmChat(
                api_key=self.api_key,
                session_id="meeting_analysis",
                system_message="–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –ø–ª–∞–Ω–µ—Ä–∫–∏. –í—ã–¥–µ–ª—è–π –∫–ª—é—á–µ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –∑–∞–¥–∞—á–∏."
            ).with_model("openai", "gpt-4o-mini")
            
            response = await chat.send_message(UserMessage(text=analysis_prompt))
            
            return {
                "summary": response,
                "timestamp": datetime.utcnow().isoformat(),
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"Meeting analysis error: {e}")
            return {
                "summary": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø–ª–∞–Ω–µ—Ä–∫–∏",
                "status": "error",
                "error": str(e)
            }

    async def generate_financial_report(self, financial_data: Dict) -> str:
        """Generate financial analysis report"""
        try:
            report_prompt = f"""
–°–æ–∑–¥–∞–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö:

–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:
- –í—ã—Ä—É—á–∫–∞: {financial_data.get('revenue', 0)} —Ä—É–±
- –†–∞—Å—Ö–æ–¥—ã: {financial_data.get('expenses', 0)} —Ä—É–±  
- –ü—Ä–∏–±—ã–ª—å: {financial_data.get('profit', 0)} —Ä—É–±

–î–∞–π –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π.
"""

            chat = LlmChat(
                api_key=self.api_key,
                session_id="financial_report",
                system_message="–¢—ã —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏ –¥–∞–≤–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
            ).with_model("openai", "gpt-4o-mini")
            
            response = await chat.send_message(UserMessage(text=report_prompt))
            return response
            
        except Exception as e:
            logger.error(f"Financial report error: {e}")
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"

# Global AI assistant instance
ai_assistant = AIAssistant()