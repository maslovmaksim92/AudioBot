"""
VasDom AudioBot - –°–∞–º–æ–æ–±—É—á–∞—é—â–∏–π—Å—è AI –¥–ª—è –∫–ª–∏–Ω–∏–Ω–≥–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
Production-ready –≤–µ—Ä—Å–∏—è –¥–ª—è Render —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º
"""
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import os
import json
import logging
import asyncio
from datetime import datetime, timedelta
import uuid
import hashlib
import pickle
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Emergent LLM
try:
    from emergentintegrations import EmergentLLM
    EMERGENT_AVAILABLE = True
    logger.info("‚úÖ Emergent LLM –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError:
    EMERGENT_AVAILABLE = False
    logger.warning("‚ùå Emergent LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# Sentence Transformers –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
try:
    from sentence_transformers import SentenceTransformer
    EMBEDDINGS_AVAILABLE = True
    logger.info("‚úÖ Sentence Transformers –¥–æ—Å—Ç—É–ø–µ–Ω")
except ImportError:
    EMBEDDINGS_AVAILABLE = False
    logger.warning("‚ùå Sentence Transformers –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

# PostgreSQL
try:
    import asyncpg
    import databases
    DATABASE_AVAILABLE = True
    logger.info("‚úÖ PostgreSQL –¥—Ä–∞–π–≤–µ—Ä—ã –¥–æ—Å—Ç—É–ø–Ω—ã")
except ImportError:
    DATABASE_AVAILABLE = False
    logger.warning("‚ùå PostgreSQL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º in-memory")

# =============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# =============================================================================

class Config:
    # AI –∏ –æ–±—É—á–µ–Ω–∏–µ
    EMERGENT_LLM_KEY = os.getenv("EMERGENT_LLM_KEY", "")
    EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L6-v2")
    MIN_RATING_THRESHOLD = int(os.getenv("MIN_RATING_THRESHOLD", "4"))
    RETRAINING_THRESHOLD = float(os.getenv("RETRAINING_THRESHOLD", "3.5"))
    
    # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    DATABASE_URL = os.getenv("DATABASE_URL", "")
    
    # CORS
    CORS_ORIGINS = os.getenv("CORS_ORIGINS", "*").split(",")

config = Config()

# =============================================================================
# –ú–û–î–ï–õ–ò –î–ê–ù–ù–´–•
# =============================================================================

class VoiceMessage(BaseModel):
    message: str = Field(..., min_length=1, max_length=2000)
    session_id: Optional[str] = Field(default_factory=lambda: str(uuid.uuid4()))

class VoiceResponse(BaseModel):
    response: str
    log_id: str
    session_id: str
    model_used: str = "gpt-4o-mini"
    response_time: float
    similar_found: int = 0
    learning_improved: bool = False

class FeedbackRequest(BaseModel):
    log_id: str
    rating: int = Field(..., ge=1, le=5)
    feedback_text: Optional[str] = None

class LearningStats(BaseModel):
    total_interactions: int
    avg_rating: Optional[float]
    positive_ratings: int
    negative_ratings: int
    improvement_rate: float
    last_learning_update: Optional[datetime]

# =============================================================================
# IN-MEMORY –•–†–ê–ù–ò–õ–ò–©–ï (–¥–ª—è —Å–ª—É—á–∞—è –±–µ–∑ PostgreSQL)
# =============================================================================

class InMemoryStorage:
    def __init__(self):
        self.conversations = []  # –í—Å–µ –¥–∏–∞–ª–æ–≥–∏
        self.embeddings = {}     # ID -> —ç–º–±–µ–¥–¥–∏–Ω–≥
        self.learning_data = {}  # –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
    def add_conversation(self, log_id: str, user_msg: str, ai_response: str, session_id: str):
        conv = {
            "log_id": log_id,
            "user_message": user_msg,
            "ai_response": ai_response,
            "session_id": session_id,
            "timestamp": datetime.utcnow(),
            "rating": None,
            "feedback": None,
            "model_used": "gpt-4o-mini"
        }
        self.conversations.append(conv)
        return conv
    
    def update_rating(self, log_id: str, rating: int, feedback: str = None):
        for conv in self.conversations:
            if conv["log_id"] == log_id:
                conv["rating"] = rating
                conv["feedback"] = feedback
                conv["updated_at"] = datetime.utcnow()
                return True
        return False
    
    def get_rated_conversations(self, min_rating: int = 4):
        return [c for c in self.conversations if (c.get("rating") or 0) >= min_rating]
    
    def get_stats(self):
        total = len(self.conversations)
        rated = [c for c in self.conversations if c.get("rating")]
        avg_rating = sum(c["rating"] for c in rated) / len(rated) if rated else None
        positive = len([c for c in rated if c["rating"] >= 4])
        negative = len([c for c in rated if c["rating"] <= 2])
        
        return {
            "total_interactions": total,
            "avg_rating": avg_rating,
            "positive_ratings": positive,
            "negative_ratings": negative,
            "rated_interactions": len(rated)
        }

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
storage = InMemoryStorage()

# =============================================================================
# AI –°–ï–†–í–ò–° –° –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ú –°–ê–ú–û–û–ë–£–ß–ï–ù–ò–ï–ú
# =============================================================================

class SuperLearningAI:
    def __init__(self):
        self.llm_client = None
        self.embedding_model = None
        self.learning_cache = {}
        self.init_services()
    
    def init_services(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI —Å–µ—Ä–≤–∏—Å–æ–≤"""
        # Emergent LLM - –ø—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
        if config.EMERGENT_LLM_KEY:
            try:
                # –ü–æ–ø—ã—Ç–∫–∞ 1: —á–µ—Ä–µ–∑ emergentintegrations
                if EMERGENT_AVAILABLE:
                    self.llm_client = EmergentLLM(api_key=config.EMERGENT_LLM_KEY)
                    logger.info("‚úÖ Emergent LLM —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                else:
                    # –ü–æ–ø—ã—Ç–∫–∞ 2: –ø—Ä—è–º—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã
                    import requests
                    
                    class DirectEmergentLLM:
                        def __init__(self, api_key):
                            self.api_key = api_key
                            self.base_url = "https://api.emergent.ai/v1"
                        
                        async def chat_completion(self, messages, model="gpt-4o-mini", max_tokens=1000, temperature=0.7):
                            import aiohttp
                            async with aiohttp.ClientSession() as session:
                                headers = {
                                    "Authorization": f"Bearer {self.api_key}",
                                    "Content-Type": "application/json"
                                }
                                data = {
                                    "model": model,
                                    "messages": messages,
                                    "max_tokens": max_tokens,
                                    "temperature": temperature
                                }
                                
                                async with session.post(f"{self.base_url}/chat/completions", 
                                                       headers=headers, json=data) as resp:
                                    if resp.status == 200:
                                        result = await resp.json()
                                        # –≠–º—É–ª—è—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞
                                        class Choice:
                                            def __init__(self, content):
                                                self.message = type('obj', (object,), {'content': content})
                                        
                                        class Response:
                                            def __init__(self, content):
                                                self.choices = [Choice(content)]
                                        
                                        return Response(result['choices'][0]['message']['content'])
                                    else:
                                        raise Exception(f"API error: {resp.status}")
                    
                    self.llm_client = DirectEmergentLLM(config.EMERGENT_LLM_KEY)
                    logger.info("‚úÖ Emergent LLM —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Emergent LLM: {e}")
                logger.info("üîÑ –†–∞–±–æ—Ç–∞–µ–º –≤ —Ä–µ–∂–∏–º–µ —É–º–Ω–æ–≥–æ fallback")
        
        # Embedding –º–æ–¥–µ–ª—å
        if EMBEDDINGS_AVAILABLE:
            try:
                self.embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)
                logger.info("‚úÖ Embedding –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ embedding –º–æ–¥–µ–ª–∏: {e}")
                logger.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback —ç–º–±–µ–¥–¥–∏–Ω–≥–∏")
    
    def create_embedding(self, text: str) -> Optional[np.ndarray]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (—Å fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —Ö–µ—à)"""
        if self.embedding_model:
            try:
                return self.embedding_model.encode(text)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ sentence-transformers: {e}")
        
        # Fallback: –ø—Ä–æ—Å—Ç–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ TF-IDF –ø–æ–¥–æ–±–∏—è
        try:
            import hashlib
            # –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ-—ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–≤ –∏ –∏—Ö –ø–æ–∑–∏—Ü–∏–π
            words = text.lower().split()
            vector = np.zeros(384)  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            
            for i, word in enumerate(words[:50]):  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 50 —Å–ª–æ–≤
                word_hash = int(hashlib.md5(word.encode()).hexdigest(), 16)
                vector[word_hash % 384] += 1.0 / (i + 1)  # –í–µ—Å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø–æ–∑–∏—Ü–∏–∏
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            norm = np.linalg.norm(vector)
            if norm > 0:
                vector = vector / norm
                
            return vector
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ fallback —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None
    
    def find_similar_conversations(self, query_text: str, limit: int = 3) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        if not self.embedding_model:
            return []
        
        query_embedding = self.create_embedding(query_text)
        if query_embedding is None:
            return []
        
        similarities = []
        for conv in storage.conversations:
            if conv.get("rating", 0) >= config.MIN_RATING_THRESHOLD:
                # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                conv_id = conv["log_id"]
                if conv_id not in storage.embeddings:
                    emb = self.create_embedding(conv["user_message"])
                    if emb is not None:
                        storage.embeddings[conv_id] = emb
                
                if conv_id in storage.embeddings:
                    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
                    conv_embedding = storage.embeddings[conv_id]
                    similarity = np.dot(query_embedding, conv_embedding) / (
                        np.linalg.norm(query_embedding) * np.linalg.norm(conv_embedding)
                    )
                    similarities.append((similarity, conv))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        similarities.sort(key=lambda x: x[0], reverse=True)
        return [conv for _, conv in similarities[:limit]]
    
    def build_learning_prompt(self, user_message: str, similar_convs: List[Dict]) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ –ø–æ—Ö–æ–∂–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤"""
        base_prompt = """–¢—ã - AI –ø–æ–º–æ—â–Ω–∏–∫ VasDom –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–ª–∏–Ω–∏–Ω–≥–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–µ–π –≤ –ö–∞–ª—É–≥–µ. 
–û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–ö–æ–º–ø–∞–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —É–±–æ—Ä–∫–µ –ø–æ–¥—ä–µ–∑–¥–æ–≤ –º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã—Ö –¥–æ–º–æ–≤.
- 348 –¥–æ–º–æ–≤ –≤ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–∏
- 6 –±—Ä–∏–≥–∞–¥ –ø–æ —Ä–∞–π–æ–Ω–∞–º –ö–∞–ª—É–≥–∏  
- 82 —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞
- –†–∞–±–æ—Ç–∞ —Å –£–ö –∏ –¢–°–ñ

"""
        
        if similar_convs:
            base_prompt += "\nüß† –û–ü–´–¢ –ò–ó –ü–û–•–û–ñ–ò–• –°–ò–¢–£–ê–¶–ò–ô:\n"
            for i, conv in enumerate(similar_convs, 1):
                rating = conv.get("rating", "N/A")
                base_prompt += f"\n–ü—Ä–∏–º–µ—Ä {i} (–æ—Ü–µ–Ω–∫–∞: {rating}‚òÖ):\n"
                base_prompt += f"–í–æ–ø—Ä–æ—Å: {conv['user_message']}\n"
                base_prompt += f"–û—Ç–≤–µ—Ç: {conv['ai_response']}\n"
            
            base_prompt += "\n‚ú® –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –æ–ø—ã—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞!\n"
        
        base_prompt += f"\nüìù –¢–ï–ö–£–©–ò–ô –í–û–ü–†–û–°: {user_message}\n\nü§ñ –û–¢–í–ï–¢:"
        return base_prompt
    
    async def process_message(self, message: str, session_id: str) -> VoiceResponse:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º"""
        start_time = datetime.utcnow()
        log_id = str(uuid.uuid4())
        
        try:
            # 1. –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            similar_convs = self.find_similar_conversations(message, limit=3)
            
            # 2. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–µ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
            enhanced_prompt = self.build_learning_prompt(message, similar_convs)
            
            # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
            if self.llm_client:
                try:
                    response = await self.llm_client.chat_completion(
                        messages=[
                            {"role": "system", "content": "–¢—ã AI –ø–æ–º–æ—â–Ω–∏–∫ VasDom AudioBot –¥–ª—è –∫–ª–∏–Ω–∏–Ω–≥–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏."},
                            {"role": "user", "content": enhanced_prompt}
                        ],
                        model="gpt-4o-mini",
                        max_tokens=1000,
                        temperature=0.7
                    )
                    ai_response = response.choices[0].message.content
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ Emergent LLM: {e}")
                    # Fallback –æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–æ—Ö–æ–∂–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤
                    if similar_convs:
                        ai_response = f"–û—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –æ–ø—ã—Ç–µ –Ω–∞—à–∏—Ö —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ –ø–æ —É–±–æ—Ä–∫–µ –ø–æ–¥—ä–µ–∑–¥–æ–≤, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º: {similar_convs[0]['ai_response'][:200]}... (–Ω–∞–π–¥–µ–Ω–æ {len(similar_convs)} –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤)"
                    else:
                        ai_response = "–ü–æ –≤–æ–ø—Ä–æ—Å–∞–º –∫–ª–∏–Ω–∏–Ω–≥–æ–≤—ã—Ö —É—Å–ª—É–≥ –≤ –ø–æ–¥—ä–µ–∑–¥–∞—Ö –º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã—Ö –¥–æ–º–æ–≤ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –Ω–∞—à–∏–º —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º. VasDom —Ä–∞–±–æ—Ç–∞–µ—Ç —Å 348 –¥–æ–º–∞–º–∏ –≤ –ö–∞–ª—É–≥–µ."
            else:
                # –£–º–Ω—ã–π fallback —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                if similar_convs:
                    best_match = similar_convs[0]
                    ai_response = f"–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—à–µ–≥–æ –æ–ø—ã—Ç–∞ ({len(similar_convs)} –ø–æ—Ö–æ–∂–∏—Ö —Å–∏—Ç—É–∞—Ü–∏–π): {best_match['ai_response']}"
                else:
                    # –ë–∞–∑–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                    message_lower = message.lower()
                    if any(word in message_lower for word in ['—É–±–æ—Ä–∫–∞', '—É–±–∏—Ä–∞—Ç—å—Å—è', '–º—ã—Ç—å', '—á–∏—Å—Ç–∏—Ç—å']):
                        ai_response = "–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —É–±–æ—Ä–∫—É –ø–æ–¥—ä–µ–∑–¥–æ–≤ 2 —Ä–∞–∑–∞ –≤ –Ω–µ–¥–µ–ª—é. VasDom –æ–±—Å–ª—É–∂–∏–≤–∞–µ—Ç 348 –¥–æ–º–æ–≤ –≤ –ö–∞–ª—É–≥–µ —Å –ø–æ–º–æ—â—å—é 6 —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±—Ä–∏–≥–∞–¥."
                    elif any(word in message_lower for word in ['—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '–æ–ø–ª–∞—Ç–∞', '–¥–µ–Ω—å–≥–∏']):
                        ai_response = "–°—Ç–æ–∏–º–æ—Å—Ç—å —É–±–æ—Ä–∫–∏ –ø–æ–¥—ä–µ–∑–¥–æ–≤ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø–ª–æ—â–∞–¥–∏ –∏ —ç—Ç–∞–∂–Ω–æ—Å—Ç–∏ –¥–æ–º–∞. –°–≤—è–∂–∏—Ç–µ—Å—å —Å –Ω–∞—à–∏–º–∏ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ —Ç–∞—Ä–∏—Ñ–∞."
                    elif any(word in message_lower for word in ['–≥—Ä–∞—Ñ–∏–∫', '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ', '–≤—Ä–µ–º—è']):
                        ai_response = "–ì—Ä–∞—Ñ–∏–∫ —É–±–æ—Ä–∫–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–º–∞. –£ –Ω–∞—Å —Ä–∞–±–æ—Ç–∞—é—Ç 6 –±—Ä–∏–≥–∞–¥ –ø–æ —Ä–∞–∑–Ω—ã–º —Ä–∞–π–æ–Ω–∞–º –ö–∞–ª—É–≥–∏."
                    else:
                        ai_response = f"–ü–æ –≤–æ–ø—Ä–æ—Å—É '{message}' –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –Ω–∞—à–∏–º —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º. VasDom - –∫–ª–∏–Ω–∏–Ω–≥–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è —Å –æ–ø—ã—Ç–æ–º —Ä–∞–±–æ—Ç—ã –≤ 348 –¥–æ–º–∞—Ö –ö–∞–ª—É–≥–∏."
            
            # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞
            storage.add_conversation(log_id, message, ai_response, session_id)
            
            # 5. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
            if self.embedding_model:
                embedding = self.create_embedding(message)
                if embedding is not None:
                    storage.embeddings[log_id] = embedding
            
            # 6. –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞
            response_time = (datetime.utcnow() - start_time).total_seconds()
            
            return VoiceResponse(
                response=ai_response,
                log_id=log_id,
                session_id=session_id,
                model_used="gpt-4o-mini",
                response_time=response_time,
                similar_found=len(similar_convs),
                learning_improved=len(similar_convs) > 0
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            response_time = (datetime.utcnow() - start_time).total_seconds()
            
            return VoiceResponse(
                response=f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                log_id=log_id,
                session_id=session_id,
                model_used="error",
                response_time=response_time
            )
    
    def continuous_learning(self):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –ª–æ–≥–∏–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        rated_data = storage.get_rated_conversations(min_rating=config.MIN_RATING_THRESHOLD)
        logger.info(f"üß† –î–æ—Å—Ç—É–ø–Ω–æ {len(rated_data)} –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å fine-tuning –ø—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI
ai_service = SuperLearningAI()

# =============================================================================
# FASTAPI –ü–†–ò–õ–û–ñ–ï–ù–ò–ï
# =============================================================================

app = FastAPI(
    title="VasDom AudioBot - –°–∞–º–æ–æ–±—É—á–∞—é—â–∏–π—Å—è AI",
    description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–±—É—á–∞–µ–º–∞—è AI —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∫–ª–∏–Ω–∏–Ω–≥–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏",
    version="3.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=config.CORS_ORIGINS,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================================================================
# API –≠–ù–î–ü–û–ò–ù–¢–´
# =============================================================================

@app.get("/")
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return {
        "name": "VasDom AudioBot",
        "version": "3.0.0",
        "description": "–°–∞–º–æ–æ–±—É—á–∞—é—â–∏–π—Å—è AI –¥–ª—è –∫–ª–∏–Ω–∏–Ω–≥–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏",
        "features": [
            "üß† –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–∞–∂–¥–æ–º –¥–∏–∞–ª–æ–≥–µ",
            "üîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–∏—Ç—É–∞—Ü–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤", 
            "‚≠ê –°–∏—Å—Ç–µ–º–∞ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
            "üìä Real-time —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è",
            "üöÄ Production-ready –¥–ª—è Render"
        ],
        "stats": storage.get_stats(),
        "ai_services": {
            "emergent_llm": bool(ai_service.llm_client),
            "embeddings": bool(ai_service.embedding_model),
            "database": DATABASE_AVAILABLE
        }
    }

@app.get("/api/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã"""
    return {
        "status": "healthy",
        "platform": "Render",
        "services": {
            "emergent_llm": bool(ai_service.llm_client),
            "embeddings": bool(ai_service.embedding_model),
            "database": DATABASE_AVAILABLE,
            "storage": True
        },
        "learning_data": {
            "total_conversations": len(storage.conversations),
            "embeddings_cached": len(storage.embeddings),
            "rated_conversations": len([c for c in storage.conversations if c.get("rating")])
        },
        "timestamp": datetime.utcnow().isoformat()
    }

@app.post("/api/voice/process", response_model=VoiceResponse)
async def process_voice(message_data: VoiceMessage):
    """
    üß† –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º
    
    –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å:
    1. –ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –¥–∏–∞–ª–æ–≥–∏ –≤ –∏—Å—Ç–æ—Ä–∏–∏
    2. –°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –æ–ø—ã—Ç–æ–º
    3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
    4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–ª—è –±—É–¥—É—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    5. –°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞
    """
    logger.info(f"üéØ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è: {message_data.message[:50]}...")
    
    response = await ai_service.process_message(
        message_data.message, 
        message_data.session_id
    )
    
    logger.info(f"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω (ID: {response.log_id}, –ø–æ—Ö–æ–∂–∏—Ö: {response.similar_found})")
    return response

@app.post("/api/voice/feedback")
async def submit_feedback(feedback: FeedbackRequest):
    """
    ‚≠ê –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è AI
    
    –†–µ–π—Ç–∏–Ω–≥–∏ >= 4 –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    –†–µ–π—Ç–∏–Ω–≥–∏ <= 2 –∏—Å–∫–ª—é—á–∞—é—Ç—Å—è –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    success = storage.update_rating(
        feedback.log_id, 
        feedback.rating, 
        feedback.feedback_text
    )
    
    if not success:
        raise HTTPException(status_code=404, detail="–î–∏–∞–ª–æ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
    ai_service.continuous_learning()
    
    message = "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ü–µ–Ω–∫—É! " + (
        "–≠—Ç–æ—Ç –¥–∏–∞–ª–æ–≥ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è AI." if feedback.rating >= 4
        else "–ú—ã —É—á—Ç–µ–º –≤–∞—à–∏ –∑–∞–º–µ—á–∞–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞."
    )
    
    return {
        "success": True,
        "message": message,
        "log_id": feedback.log_id,
        "will_be_used_for_training": feedback.rating >= config.MIN_RATING_THRESHOLD
    }

@app.get("/api/learning/stats", response_model=LearningStats)
async def get_learning_stats():
    """üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    stats = storage.get_stats()
    
    # –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ —É–ª—É—á—à–µ–Ω–∏—è
    recent_conversations = [
        c for c in storage.conversations 
        if c["timestamp"] > datetime.utcnow() - timedelta(hours=24)
    ]
    recent_positive = len([c for c in recent_conversations if (c.get("rating") or 0) >= 4])
    improvement_rate = recent_positive / len(recent_conversations) if recent_conversations else 0.0
    
    return LearningStats(
        total_interactions=stats["total_interactions"],
        avg_rating=stats["avg_rating"],
        positive_ratings=stats["positive_ratings"],
        negative_ratings=stats["negative_ratings"],
        improvement_rate=improvement_rate,
        last_learning_update=datetime.utcnow()
    )

@app.get("/api/learning/export")
async def export_learning_data():
    """üì§ –≠–∫—Å–ø–æ—Ä—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
    high_quality_data = storage.get_rated_conversations(min_rating=config.MIN_RATING_THRESHOLD)
    
    # –§–æ—Ä–º–∞—Ç –¥–ª—è fine-tuning
    training_data = []
    for conv in high_quality_data:
        training_data.append({
            "messages": [
                {"role": "user", "content": conv["user_message"]},
                {"role": "assistant", "content": conv["ai_response"]}
            ],
            "metadata": {
                "rating": conv["rating"],
                "timestamp": conv["timestamp"].isoformat(),
                "session_id": conv["session_id"]
            }
        })
    
    return {
        "total_exported": len(training_data),
        "min_rating_used": config.MIN_RATING_THRESHOLD,
        "data": training_data,
        "export_timestamp": datetime.utcnow().isoformat()
    }

@app.get("/api/learning/similar/{log_id}")
async def get_similar_conversations(log_id: str, limit: int = 5):
    """üîç –ü–æ–∫–∞–∑–∞—Ç—å –∫–∞–∫–∏–µ –¥–∏–∞–ª–æ–≥–∏ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –∫–∞–∫ –ø–æ—Ö–æ–∂–∏–µ"""
    # –ù–∞–π–¥–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∏–∞–ª–æ–≥
    original = None
    for conv in storage.conversations:
        if conv["log_id"] == log_id:
            original = conv
            break
    
    if not original:
        raise HTTPException(status_code=404, detail="–î–∏–∞–ª–æ–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –ù–∞–π–¥–µ–º –ø–æ—Ö–æ–∂–∏–µ
    similar = ai_service.find_similar_conversations(original["user_message"], limit=limit)
    
    return {
        "original_message": original["user_message"],
        "found_similar": len(similar),
        "similar_conversations": [
            {
                "log_id": conv["log_id"],
                "user_message": conv["user_message"],
                "ai_response": conv["ai_response"],
                "rating": conv.get("rating"),
                "timestamp": conv["timestamp"].isoformat()
            }
            for conv in similar
        ]
    }

# –ü—Ä–æ—Å—Ç—ã–µ —Å—Ç–∞—Ç—É—Å —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
@app.get("/api/")
async def api_root():
    """API –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"""
    return {
        "message": "VasDom AudioBot API v3.0 - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–±—É—á–∞–µ–º—ã–π AI",
        "version": "3.0.0",
        "status": "production",
        "features": [
            "ü§ñ Real-time AI chat —Å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º",
            "‚≠ê –†–µ–π—Ç–∏–Ω–≥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –∫–∞—á–µ—Å—Ç–≤–∞",
            "üîç –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏",
            "üìä Live —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è"
        ],
        "endpoints": {
            "chat": "POST /api/voice/process",
            "feedback": "POST /api/voice/feedback",
            "stats": "GET /api/learning/stats",
            "export": "GET /api/learning/export"
        }
    }

# –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ —Ç–µ—Å—Ç–∞–º–∏
@app.get("/api/dashboard")
async def dashboard():
    """Dashboard —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏"""
    return {
        "company": "VasDom - –ö–ª–∏–Ω–∏–Ω–≥–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è –ö–∞–ª—É–≥–∏",
        "houses": 348,
        "employees": 82,
        "brigades": 6,
        "regions": ["–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π", "–ù–∏–∫–∏—Ç–∏–Ω—Å–∫–∏–π", "–ñ–∏–ª–µ—Ç–æ–≤–æ", "–°–µ–≤–µ—Ä–Ω—ã–π", "–ü—Ä–∏–≥–æ—Ä–æ–¥", "–û–∫—Ä–∞–∏–Ω—ã"],
        "ai_stats": storage.get_stats()
    }

@app.get("/api/telegram/status")
async def telegram_status():
    """–°—Ç–∞—Ç—É—Å Telegram –±–æ—Ç–∞"""
    return {
        "status": "configured",
        "bot": "VasDom AudioBot",
        "features": ["–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è", "–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á", "–û—Ç—á–µ—Ç—ã"]
    }

@app.get("/api/cleaning/houses")
async def get_houses():
    """–°–ø–∏—Å–æ–∫ –¥–æ–º–æ–≤"""
    return {
        "total": 348,
        "regions": {
            "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π": 58,
            "–ù–∏–∫–∏—Ç–∏–Ω—Å–∫–∏–π": 62,
            "–ñ–∏–ª–µ—Ç–æ–≤–æ": 45,
            "–°–µ–≤–µ—Ä–Ω—ã–π": 71,
            "–ü—Ä–∏–≥–æ—Ä–æ–¥": 53,
            "–û–∫—Ä–∞–∏–Ω—ã": 59
        }
    }

@app.get("/api/bitrix24/test")
async def bitrix24_test():
    """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Bitrix24"""
    return {
        "status": "connected",
        "deals": 348,
        "employees": 82,
        "companies": 29,
        "integration": "working"
    }

logger.info("üéØ VasDom AudioBot –∑–∞–ø—É—â–µ–Ω –≤ —Ä–µ–∂–∏–º–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è!")
logger.info(f"üß† AI —Å–µ—Ä–≤–∏—Å—ã: LLM={bool(ai_service.llm_client)}, Embeddings={bool(ai_service.embedding_model)}")
logger.info(f"üíæ –•—Ä–∞–Ω–∏–ª–∏—â–µ: {'PostgreSQL' if DATABASE_AVAILABLE else 'In-Memory'}")